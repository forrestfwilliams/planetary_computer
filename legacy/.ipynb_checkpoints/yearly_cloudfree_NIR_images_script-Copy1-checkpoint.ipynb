{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel 2 Cloudless Mosaic\n",
    "\n",
    "This tutorial constructs a *cloudless mosaic* (also known as a composite) from a time series of [Sentinel-2 Level-2A](https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a) images and is modified from the example notebook provided by Microsoft. This notebook performs the following steps:\n",
    "\n",
    "* Find a time series of images within a bounding box\n",
    "* Stack those images together into a single array\n",
    "* Mask clouds and cloud shadows\n",
    "* Synthesize a panchromatic band by averageing Red, Green, Blue and NIR bands\n",
    "* Compute the cloudless mosaic by taking a median\n",
    "* Save the result to a GeoTiff\n",
    "\n",
    "This notebook is designed for the processing of large areas, so tasks like plotting that are useful but resource-intensive are omitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import rasterio.features\n",
    "import rioxarray\n",
    "import stackstac\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import xrspatial.multispectral as ms\n",
    "\n",
    "import dask\n",
    "from dask_gateway import GatewayCluster\n",
    "from dask import visualize\n",
    "\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import geopandas as gpd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dask cluster\n",
    "\n",
    "We're going to process a large amount of data. To cut down on the execution time, we'll use a Dask cluster to do the computation in parallel, adaptively scaling to add and remove workers as needed. See [Scale With Dask](../quickstarts/scale-with-dask.ipynb) for more on using Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the cluster\n",
    "cluster = GatewayCluster()  # Creates the Dask Scheduler. Might take a minute.\n",
    "client = cluster.get_client()\n",
    "cluster.adapt(minimum=4, maximum=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.d4ce8946d60a4a21bca42068c7e08b34/status\n"
     ]
    }
   ],
   "source": [
    "print(cluster.dashboard_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover data\n",
    "\n",
    "In this step we define our bounding box by creating a Shapely Polygon object. The Polygon object is created from a set of coordinate pairs in **Latitude and Longitude** (epsg 3857). A simple way of getting the coordinate pairs is by creating a bounding box in Google Earth, saving it to a kml, then opening it as a text file and copying the coordinates.\n",
    "\n",
    "At this point, you'll have to decide if you want to process multiple years at once, or if you want to process the years separately. This decision comes down to how much compute power you have access to. For the Dask cluster parameters specified, `cluster.adapt(minimum=4, maximum=24)`, the maximum amount of images used should be less than 200. You can alter the number of images used by changing the values of `date_range`, `max_cloud`, and `pol`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proroa: R129, T60GUA\n",
    "#andrew: R129, T60GVA\n",
    "\n",
    "# setting options\n",
    "date_range = '2016-01-01/2022-01-01'\n",
    "frame = 'T60GVA'\n",
    "orbit = 'R129'\n",
    "max_cloud_image = 33\n",
    "max_cloud_bbox = 5\n",
    "\n",
    "# get bounding box (minx, miny, maxx, maxy)\n",
    "gdf = gpd.read_file('andrew.geojson')\n",
    "bbox = tuple(gdf.total_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `pystac_client` we can search the Planetary Computer's STAC endpoint for items matching our query parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stac = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "\n",
    "search = stac.search(\n",
    "    bbox=bbox,\n",
    "    datetime=date_range,\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    limit=500,  # fetch items in batches of 500\n",
    "    query={\"eo:cloud_cover\": {\"gte\":0,\"lte\": max_cloud_image}},\n",
    ")\n",
    "\n",
    "# Get items with the correct relative orbit\n",
    "items = list(search.get_items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we restrict the results to the same orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images before cloud masking is 117\n"
     ]
    }
   ],
   "source": [
    "# grab ids\n",
    "ids = np.array([x.id.split('_') for x in items])\n",
    "\n",
    "# get correct orbit\n",
    "ids = ids[ids[:,3] == orbit]\n",
    "\n",
    "# get correct frame\n",
    "ids = ids[ids[:,4] == frame]\n",
    "\n",
    "# grab valid ids\n",
    "valid_ids = ['_'.join(x) for x in ids]\n",
    "\n",
    "#subset items\n",
    "items = [x for x in items if any([y == x.id for y in valid_ids])]\n",
    "\n",
    "print(f'Number of images before cloud masking is {len(items)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the year, this should return about 100-150 images for our study area over space, time, and cloudiness. Those items will still have *some* clouds over portions of the scenes, though. To create our cloudless mosaic, we'll load the data into an [xarray](https://xarray.pydata.org/en/stable/) DataArray using [stackstac](https://stackstac.readthedocs.io/) and then reduce the time-series of images down to a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_items = []\n",
    "for item in items:\n",
    "    item.clear_links()\n",
    "    signed_items.append(planetary_computer.sign(item).to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we load the data and perform some initial cleaing that includes:\n",
    "* subsetting to our exact bounding box\n",
    "* removing pixels that correspond clouds and clouds shadows\n",
    "\n",
    "To perform our cloud masking, we use Sentinel-2's Scene Classification Layer ([SCL](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm)) and mask out values 3, 8, 9, and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    stackstac.stack(\n",
    "        signed_items,\n",
    "        assets=[\"B08\",\"SCL\"],\n",
    "        chunksize=4096,\n",
    "        resolution=10\n",
    "    )\n",
    "    .where(lambda x: x > 0, other=np.nan)  # sentinel-2 uses 0 as nodata\n",
    ")\n",
    "\n",
    "# Get bounding box in projection of data\n",
    "minx, miny, maxx, maxy = tuple(gdf.to_crs(data.crs).total_bounds)\n",
    "\n",
    "# Subset data and mask clouds\n",
    "data = data.sel(x=slice(minx, maxx), y=slice(maxy,miny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = data.groupby('time').first(skipna=False)\n",
    "valid = xr.where(first.sel(band='SCL',drop=True).isin([3,8,9]),x=0,y=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_valid = valid.sum(dim=['x','y']).compute().to_numpy() / (data.shape[2] * data.shape[3])\n",
    "pct_valid = pct_valid.squeeze()\n",
    "dates = valid.time.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds = pd.DataFrame({'date':dates,'pct_valid':pct_valid[:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = clouds.loc[clouds.pct_valid > (100-max_cloud_bbox)/100].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best['year'] = best.date.dt.year\n",
    "counts = best.groupby('year').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2016 contains 6 images\n",
      "Year 2017 contains 15 images\n",
      "Year 2018 contains 11 images\n",
      "Year 2019 contains 13 images\n",
      "Year 2020 contains 15 images\n",
      "Year 2021 contains 12 images\n"
     ]
    }
   ],
   "source": [
    "for i,row in counts.iterrows():\n",
    "    print(f'Year {row[\"year\"]} contains {row[\"date\"]} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dates = data.sel(band=[\"B08\"],time=list(best.date)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = best_dates.groupby('time.year').median().fillna(0).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median image processing complete\n"
     ]
    }
   ],
   "source": [
    "median = median.rio.write_crs(pyproj.CRS(data.crs).to_string()).drop('proj:bbox')\n",
    "median = median.rename('Median_NIR')\n",
    "print('Median image processing complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/ssl.py\", line 1309, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1131)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/tornado/iostream.py\", line 1409, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    }
   ],
   "source": [
    "# median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = f's2_l2_{orbit}_{frame}.nc'\n",
    "# print(f'Writing to {name}...')\n",
    "# median.to_netcdf(Path('/home/jovyan/planetary_computer') / name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing s2_l2_R129_T60GVA_20160601.tif...\n",
      "Writing s2_l2_R129_T60GVA_20170601.tif...\n",
      "Writing s2_l2_R129_T60GVA_20180601.tif...\n",
      "Writing s2_l2_R129_T60GVA_20190601.tif...\n",
      "Writing s2_l2_R129_T60GVA_20200601.tif...\n",
      "Writing s2_l2_R129_T60GVA_20210601.tif...\n"
     ]
    }
   ],
   "source": [
    "for y in median.year.to_numpy():\n",
    "    name = f's2_l2_{orbit}_{frame}_{y}0601.tif'\n",
    "    print(f'Writing {name}...')\n",
    "    median.sel(year=y).rio.to_raster(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed successfully!\n"
     ]
    }
   ],
   "source": [
    "print('Completed successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close cluster\n",
    "Once we're done with our processing, let's be a good steward of our resources and close our cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "And you're done! The completed GeoTiff files should be in the same directory as this notebook, and can be downloaded via Jupyter's GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2ca0804b9f904dab815db80637a4f2d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e2f3ac516e3b4cf3a1ba1fc6aa0897ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "layout": "IPY_MODEL_2ca0804b9f904dab815db80637a4f2d9"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
